# Técnicas Estocásticas y Estadísticas para DataScience (TEEDS)

---

## Descripción

En este repositorio se encuentran los códigos utilizados en mi paso por el ramo Técnicas Estocásticas y Estadísticas para Magister Data Science de la Universidad Adolfo Ibañez impartido por la profesora Javiera Barrera, donde fui Ayudante.

**Descripción del Curso** : En este curso se revisan conceptos fundamentales de probabilidades y estadística pensado en estudiantes que proseguirán estudios en aprendizaje de máquina, análisis de datos y algoritmos.

*Disclaimer: Cabe destacar que en este repositorio sólo se encuentra todo aquellos que respecta al código, y se excluyen la materia o los ejercicios manuales.*

---

## Syllabus

1. *Probabilidades*
    1. *axiomas, variables aleatorias discretas y esperanza.*
    2. *Variables aleatorias continuas, Momentos, transformadas y dependencia.*
    3.  *Proceso de Poisson*
2. *Computabilidad*
    1. *Modelos de Bolas-Urnas y Grafos aleatorios*
    2.  *Entropía, Aleatoriedad e Información*
3. *Estadística*
    1.  *Modelos Paramétricos y Familia Exponencial*
    2.  *Métodos de Estimación de Máxima Verisimilitud*
    3. *Inferencia Clásica*
    4. *Inferencia Bayesíana Clásica*
    5. *El método "Bootstrap"*
    6. *Métodos de Montecarlo*

---

## Contenidos

### Ayudantía  1 : Probabilidades

En la primera ayudantía se realizó una especie de motivación para la materia que se venía, como un ejemplo real de las *distribuciones de probabilidad* en algunas de las variables de un dataset de Kaggle ([https://www.kaggle.com/austinreese/craigslist-carstrucks-data](https://www.kaggle.com/austinreese/craigslist-carstrucks-data)), además de una demostración simple de una simulación de la distribución de probabilidad Poisson.

Este trabajo se puede encontrar en `Ayudantía 1/Ayu1_TEEDS.ipynb`

---

### Ayudantía 2 :

En la ayudantía nº 2 se resolvieron las partes de programación de las tareas 1 y 2, en `Ayudantía 2/`  se pueden encontrar los enunciados y el código respectivo.

---

### Ayudantía 3:

En esta ayudantía no hubo programación, si no ejercicios prácticos.

---

### Ayudantía 4: Proceso de Poisson

En esta ayudantía se vieron distintas formas de simular el *Proceso de Poisson*, además de, en base a estas simulaciones, comprobar algunas de sus propiedades. Por último se resolvió el ejercicio de programación propuesta en la primera prueba (*Distribución de Bernoulli*)

Este trabajo se puede encontrar en `Ayudantia 3/Poisson_Processes.ipynb`

---

### Ayudantía 5: Cadenas de Markov

En la ayudantía 5 se vieron simulaciones de cadenas de markov. Se presentó una simulación simple de un proceso de markov, que puede encontrarse en `Ayudantía 5/markov_process.ipynb` 

Además se presentó un ejemplo más complejo y entretenido, disponible en el repositorio [https://github.com/vbelz/Markov-chain-simulation](https://github.com/vbelz/Markov-chain-simulation)

---

### Ayudantía 6: Metropolis-Hasting

Se presentó el método de Metropolis-Hasting, resolviendo la prueba de uno de los semestres. La pauta de la prueba se puede encontrar en `Ayudantía 6/ Prueba2-TEES-Pauta.pdf`  y el código respectivo en `Ayudantía 6/ tEEds_MetropolisHasting.ipynb`

---

### Ayudantía 7: Estadística Frecuentista vs Bayesiana

Se presentan una discusión con ejemplos entre los enfoques bayesianos y frecuentistas en la estadísticas.  `Ayudantía 7/ tEEds_freqvsbayes.ipynb`

---

### Ayudantía 8: Maximum Likelihood Estimation

Se resuelve un ejercicio de prueba sobre Maximum Likelihood Estimation (MLE). El enunciado se puede ver en la carpeta respectiva. `Ayudantia 8/ tEEds_MLE.ipynb`

---

### Ayudantía 9: Regresión Lasso  & Ridge

Se observan ejemplos para comparar la regresión lineal con regularización: Ridge y Lasso. `Ayudantia 9/ tEEds_Regression.ipynb`

---

### Ayudantía 10 : Jacknife & Bootstrap

Se presentan los métodos de resampleo: Jacknife y Bootstrap. `Ayudantia 10/tEEds_Jackknife_Bootstrap.ipynb`
